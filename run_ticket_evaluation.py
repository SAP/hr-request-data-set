from __future__ import annotations

import logging
from collections import defaultdict
from pprint import pprint
from typing import Union

import hydra
import pandas as pd

from ticket_generation.src.evaluate.evaluate_text import EvaluateText, EvaluationsText
from ticket_generation.src.evaluate.load_datasets import LoadDatasets
from util import load_survey_tickets_by_category, load_survey_tickets_texts, load_ticket_dataset

logging.basicConfig()
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


@hydra.main(config_path="conf/ticket_evaluation", config_name="config")
def main(cfg):

    logger.info("START")

    data_path_survey: str = cfg.data_path.data_path_survey
    data_path_amazon_reviews: str = cfg.data_path.data_path_amazon_reviews
    data_path_reddit_comments: str = cfg.data_path.data_path_reddit_comments
    data_path_nips_papers: str = cfg.data_path.data_path_nips_papers

    amazon_reviews = LoadDatasets.load_amazon_reviews_text(data_path=data_path_amazon_reviews)
    reddit_comments = LoadDatasets.load_reddit_comments_text(data_path=data_path_reddit_comments)
    # nips_papers = LoadDatasets.load_nips_papers_text(data_path=data_path_nips_papers)
    tickets_survey = load_survey_tickets_texts(data_path=data_path_survey)
    tickets_survey_by_category = load_survey_tickets_by_category(data_path=data_path_survey)

    logger.info(f"Loaded {len(tickets_survey)} tickets from survey")

    ticket_dataset: dict = cfg.ticket_dataset

    tickets_generated_by_gpt, _, labels_tickets_GPT, _, id_2_label = load_ticket_dataset(**ticket_dataset)

    tickets_generated_by_gpt_by_category: dict[str, list[str]] = defaultdict(list)

    for ticket, labels_tickets_GPT in zip(tickets_generated_by_gpt, labels_tickets_GPT):
        tickets_generated_by_gpt_by_category[id_2_label[labels_tickets_GPT]].append(ticket)

    all_tickets: list[tuple[str, list[str]]] = [
        ("Amazon reviews", amazon_reviews),
        ("Reddit comments", reddit_comments),
        # ("NIPS papers", nips_papers),
        ("Tickets generated by GPT", tickets_generated_by_gpt),
        ("Tickets survey", tickets_survey),
    ]

    # Add evaluations for each category for tickets of survey
    for category, tickets in tickets_survey_by_category.items():
        all_tickets.append((f"Tickets survey, category: {category} ({len(tickets)} tickets)", tickets))

        # Add evaluations of tickets generated by GPT for the current category if exist
        if category in tickets_generated_by_gpt_by_category.keys():
            tickets_gpt = tickets_generated_by_gpt_by_category[category]
            all_tickets.append(
                (
                    f"Tickets generated by GPT, category: {category} ({len(tickets_gpt)} tickets)",
                    tickets_gpt,
                )
            )

    all_results: list[dict[str, Union[str, float]]] = []

    text_evaluator = EvaluateText(word_frequency_path="ticket_generation/data/enwiki-word-freq-2022-08-29.csv")

    for name_dataset, tickets in all_tickets:
        result: EvaluationsText = text_evaluator.compute_all_evaluations(tickets=tickets)

        print(f"Evaluation {name_dataset}")
        pprint(result)

        all_results.append({"Dataset": name_dataset, **result})

    df_results = pd.DataFrame.from_dict(all_results)

    # Save results
    df_results.to_csv(f"ticket_generation/evaluation_output/results_text_evaluation.csv", index=False)


if __name__ == "__main__":
    main()
